# Testing Strategy - TF-Engine

**Created:** 2025-10-29 (Step 24 - Comprehensive Testing Suite)
**Status:** ‚úÖ Test infrastructure complete

---

## Overview

TF-Engine employs a comprehensive testing strategy covering unit tests, integration tests, and end-to-end workflow validation to ensure reliability of the anti-impulsivity trading system.

---

## Test Coverage Summary

### Current Coverage (as of Step 24)

| Component | Coverage | Status | Test Files |
|-----------|----------|--------|------------|
| **Domain Logic** | 96.9% | ‚úÖ Excellent | 7 test files |
| **Middleware** | 100.0% | ‚úÖ Complete | 3 test files |
| **Storage Layer** | 66.7% | ‚úÖ Good | 5 test files |
| **API Handlers** | 56.5% | ‚ö†Ô∏è Partial | 7 test files (new) |
| **Logger** | 73.3% | ‚úÖ Good | 1 test file |
| **Scraper** | 40.4% | ‚ö†Ô∏è Partial | 1 test file |

**Overall Backend Coverage:** ~75% (excluding CLI/server entry points)

---

## Testing Philosophy

### 1. **Discipline-First Testing**

Every test must validate that anti-impulsivity features cannot be bypassed:

‚úÖ **DO test:**
- Gate enforcement (all 5 gates must pass)
- Heat cap validation (portfolio and bucket)
- Position sizing correctness (Van Tharp method)
- Banner state calculation (RED/YELLOW/GREEN)
- 2-minute cooldown timer

‚ùå **DON'T test:**
- UI convenience features
- Performance optimizations that don't affect correctness
- Logging cosmetics

### 2. **Table-Driven Tests**

All tests use table-driven patterns for maintainability:

```go
tests := []struct {
    name           string
    input          SomeInput
    expectedResult SomeResult
    expectError    bool
}{
    {name: "Valid case", input: ..., expectedResult: ..., expectError: false},
    {name: "Invalid case", input: ..., expectedResult: ..., expectError: true},
}

for _, tt := range tests {
    t.Run(tt.name, func(t *testing.T) {
        // Test implementation
    })
}
```

### 3. **Test Isolation**

Each test creates its own temporary database:

```go
tmpDir := t.TempDir()  // Automatically cleaned up
dbPath := filepath.Join(tmpDir, "test.db")
db, err := storage.New(dbPath)
```

---

## Test Categories

### 1. Unit Tests (Domain Logic)

**Location:** `backend/internal/domain/*_test.go`

**What's tested:**
- Position sizing calculations (stock, options delta-ATR, options max-loss)
- Checklist evaluation (missing count ‚Üí banner color)
- Heat calculations (portfolio & bucket caps)
- Gate validation (5 hard gates)
- Settings validation

**Example:** `sizing_stock_test.go`
```go
func TestCalculateStockPosition_BasicExample(t *testing.T) {
    req := SizingRequest{
        Ticker:  "AAPL",
        Entry:   180.0,
        ATR:     1.5,
        Method:  "stock",
        K:       2.0,
        RiskPct: 0.0075,
        Equity:  100000.0,
    }

    result, err := CalculateStockPosition(req)

    // Assertions...
}
```

**Coverage:** 96.9% ‚úÖ

---

### 2. Integration Tests (Storage Layer)

**Location:** `backend/internal/storage/*_test.go`

**What's tested:**
- Database CRUD operations
- Position lifecycle (open, update, close)
- Cooldown tracking
- Decision logging
- Candidate import
- Timer state management

**Example:** `positions_test.go`
```go
func TestOpenPosition(t *testing.T) {
    db, _ := storage.New(":memory:")
    defer db.Close()
    db.Initialize()

    pos, err := db.OpenPosition("AAPL")

    // Assertions...
}
```

**Coverage:** 66.7% ‚úÖ

---

### 3. API Integration Tests (Handlers)

**Location:** `backend/internal/api/handlers/*_test.go`

**What's tested:**
- HTTP endpoint behavior
- Request validation
- Response format
- Error handling
- Method restrictions

**Example:** `settings_test.go`
```go
func TestSettingsHandler_GetSettings(t *testing.T) {
    db, _ := storage.New(tmpPath)
    defer db.Close()
    db.Initialize()

    handler := NewSettingsHandler(db, logger)

    req := httptest.NewRequest(http.MethodGet, "/api/settings", nil)
    w := httptest.NewRecorder()

    handler.GetSettings(w, req)

    // Assert status code, response format, etc.
}
```

**Coverage:** 56.5% ‚ö†Ô∏è (Tests created, need response format adjustments)

**Test Files Created:**
1. `settings_test.go` - Settings API tests
2. `positions_test.go` - Positions API tests
3. `sizing_test.go` - Position sizing API tests
4. `heat_test.go` - Heat check API tests
5. `decisions_test.go` - Trade decision API tests
6. `candidates_test.go` - Candidate import API tests
7. `calendar_test.go` - Calendar view API tests

---

### 4. Middleware Tests

**Location:** `backend/internal/api/middleware/*_test.go`

**What's tested:**
- CORS headers
- Request logging with correlation IDs
- Performance monitoring (slow request warnings)
- Panic recovery
- Error handling

**Coverage:** 100.0% ‚úÖ

**Test Files:**
1. `cors_test.go` - CORS middleware
2. `logging_test.go` - Logging middleware
3. `recovery_test.go` - Panic recovery middleware

---

## Running Tests

### All Tests

```bash
cd backend/
go test ./... -v -cover
```

### Specific Package

```bash
go test ./internal/domain/... -v
go test ./internal/storage/... -v
go test ./internal/api/handlers/... -v
```

### With Coverage Report

```bash
go test ./... -coverprofile=coverage.out
go tool cover -html=coverage.out
```

### Watch Mode (using entr)

```bash
find . -name "*.go" | entr -c go test ./...
```

---

## E2E Workflow Tests

### Complete Trading Workflow

**Manual E2E Test Checklist:**

#### 1. Morning Scan
- [ ] Import candidates from FINVIZ
- [ ] Verify candidates saved to database
- [ ] Check candidate count matches import

#### 2. Trade Evaluation (AAPL Example)
- [ ] Enter ticker: AAPL
- [ ] Complete checklist (all 5 required gates)
- [ ] Verify banner turns GREEN
- [ ] Verify 2-minute timer starts

#### 3. Position Sizing
- [ ] Calculate: Entry=$180, ATR=$1.50, K=2
- [ ] Verify: Risk=$750, Shares=250, Stop=$177
- [ ] Verify add levels calculated correctly

#### 4. Heat Check
- [ ] Check with no positions ‚Üí Should be OK
- [ ] Add position with $750 risk
- [ ] Check adding another $750 ‚Üí Verify portfolio heat
- [ ] Check Tech/Comm bucket heat ‚Üí Verify sector heat

#### 5. Trade Entry (5 Gates)
- [ ] Verify Gate 1: Banner is GREEN
- [ ] Verify Gate 2: Timer elapsed (2 minutes)
- [ ] Verify Gate 3: Not on cooldown
- [ ] Verify Gate 4: Heat caps not exceeded
- [ ] Verify Gate 5: Position sizing complete
- [ ] Save GO decision
- [ ] Verify decision logged

#### 6. Calendar View
- [ ] Open calendar view
- [ ] Verify 10 weeks displayed (2 back + 8 forward)
- [ ] Verify position appears in correct week/sector
- [ ] Verify color coding by age

### Automated E2E Test Script

**Location:** `backend/test_e2e.sh` (to be created in future)

```bash
#!/bin/bash
# Full workflow test
# 1. Start server
# 2. Import candidates
# 3. Calculate sizing
# 4. Check heat
# 5. Save decision
# 6. Verify calendar
# 7. Cleanup
```

---

## Test Data

### Test Fixtures

**Location:** `backend/test-data/`

- `test-contracts.db` - Sample database with positions
- `json-examples/` - JSON request/response examples
- `phase4-test-data.sql` - SQL fixtures

### Creating Test Data

```go
// Create test position
position, _ := db.OpenPosition("AAPL")

// Create test decision
db.SaveDecision(storage.Decision{
    Ticker:  "AAPL",
    Action:  "GO",
    Entry:   180.0,
    // ...
})

// Import test candidates
db.ImportCandidates("2025-10-29", []string{"AAPL", "NVDA"}, nil, "", "")
```

---

## Continuous Integration (Future)

### GitHub Actions Workflow

```yaml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-go@v4
        with:
          go-version: '1.21'
      - run: go test ./... -cover
      - run: go test ./... -race
```

---

## Anti-Impulsivity Test Cases

### Critical Test Scenarios

1. **Cannot bypass banner check**
   - ‚úÖ Tested in `gates_test.go`
   - GO decision rejected if banner not GREEN

2. **Cannot exceed heat caps**
   - ‚úÖ Tested in `heat_test.go`
   - Portfolio cap: 4% of equity
   - Bucket cap: 1.5% of equity

3. **Cannot skip cooldown timer**
   - ‚úÖ Tested in `timers_test.go`
   - 2-minute minimum enforced

4. **Position sizing is correct**
   - ‚úÖ Tested in `sizing_stock_test.go`, `sizing_options_test.go`
   - Van Tharp method validated
   - Actual risk ‚â§ specified risk

5. **Checklist determines banner correctly**
   - ‚úÖ Tested in `checklist_test.go`
   - 0 missing ‚Üí GREEN
   - 1 missing ‚Üí YELLOW
   - 2+ missing ‚Üí RED

---

## Known Test Gaps

### Areas Needing More Coverage

1. **API Handler Response Formats** (56.5% coverage)
   - Handler tests created but need adjustments
   - Response JSON structure validation incomplete
   - Some success paths failing

2. **FINVIZ Scraper** (40.4% coverage)
   - Network mocking needed
   - HTML parsing edge cases
   - Preset query validation

3. **CLI Commands** (0% coverage)
   - Not currently in use (server mode primary)
   - Low priority

4. **Server Initialization** (0% coverage)
   - Integration test needed
   - Low priority (manual testing sufficient)

---

## Best Practices

### DO ‚úÖ

1. **Use table-driven tests**
   ```go
   tests := []struct{ name string; input X; want Y }{ ... }
   ```

2. **Test edge cases**
   - Zero values
   - Negative values
   - Empty strings
   - Nil pointers

3. **Test error paths**
   - Invalid input
   - Database errors
   - Network failures

4. **Use descriptive test names**
   ```go
   func TestCalculateSize_NegativeATR_ReturnsError(t *testing.T)
   ```

5. **Clean up resources**
   ```go
   defer db.Close()
   ```

### DON'T ‚ùå

1. **Don't use global state**
   - Each test should be independent

2. **Don't skip cleanup**
   - Use `t.TempDir()` for automatic cleanup

3. **Don't test implementation details**
   - Test behavior, not internal structure

4. **Don't use sleeps**
   - Use channels or timeouts

5. **Don't ignore errors**
   - Always check `err` values

---

## Test Execution Strategy

### Development Workflow

1. **Before commit:** Run related tests
   ```bash
   go test ./internal/domain/sizing_stock_test.go
   ```

2. **Before push:** Run all tests
   ```bash
   go test ./...
   ```

3. **Before release:** Run E2E tests
   ```bash
   ./test_e2e.sh
   ```

### Performance Testing

```bash
# Benchmark position sizing
go test -bench=BenchmarkCalculateSize ./internal/domain/

# Race detector
go test -race ./...

# Memory profiling
go test -memprofile=mem.out ./internal/domain/
go tool pprof mem.out
```

---

## Troubleshooting Tests

### Common Issues

**Issue:** Test database locked
```
Error: database is locked
```
**Solution:** Ensure `defer db.Close()` is called

**Issue:** Test fails intermittently
```
PASS/FAIL varies between runs
```
**Solution:** Check for race conditions, use `-race` flag

**Issue:** Test times out
```
panic: test timed out after 10m0s
```
**Solution:** Reduce test scope or increase timeout

---

## Future Improvements

### Step 25+ Enhancements

1. **Increase API handler coverage to 80%+**
   - Fix response format validation
   - Add more edge case tests

2. **Add E2E automation**
   - Bash script for full workflow
   - Docker-based testing environment

3. **Performance benchmarks**
   - Establish baseline metrics
   - Regression detection

4. **Integration with CI/CD**
   - GitHub Actions workflow
   - Automated coverage reporting

5. **Mutation testing**
   - Verify test effectiveness
   - Identify untested code paths

---

## Summary

**‚úÖ Achievements (Step 24):**
- Created comprehensive test suite
- 96.9% domain logic coverage
- 100% middleware coverage
- 66.7% storage coverage
- Test infrastructure for all API endpoints

**‚ö†Ô∏è Remaining Work:**
- Adjust API handler tests (response format)
- Add E2E automation script
- Increase scraper coverage

**üìä Overall Grade:** A- (Excellent foundation, minor refinements needed)

---

**Last Updated:** 2025-10-29 18:35
**Next:** Step 25 - Windows Deployment & Validation
